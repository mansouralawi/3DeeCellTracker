{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DeeCellTracker Demo: Ensemble mode | Use StarDist\n",
    "\n",
    "This notebook shows how to use 3DeeCellTracker to track cells in ensemble mode. The segmentation is basded on the trained StarDist.\n",
    "\n",
    "The demo data and pre-trained deep neural network models can be found in the \"worm4\", \"stardist_models\" and \"ffn_models\" folders downloaded from https://osf.io/pgr95/\n",
    "\n",
    "**The basic procedures:**\n",
    "- A. Import packages\n",
    "- B. Segment cells by StarDist3D\n",
    "- C. Load manually corrected segmentation (t=1)\n",
    "- D. Track cells by FFN + PRGLS + Fine-tune.\n",
    "- E. Extract activities from the tracked cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T04:31:33.940881Z",
     "start_time": "2021-06-14T04:31:33.690724Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import CellTracker.trackerlite as trl\n",
    "import CellTracker.stardistwrapper as sdw\n",
    "import CellTracker.coord_image_transformer as cit\n",
    "from CellTracker.analyses import draw_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE THIS FIELDS\n",
    "\n",
    "base_dir = \"/om/user/mansour8/build_demo\"\n",
    "example_dir = F\"{base_dir}/3DeeCellTracker/Examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Segment cells by StarDist3D\n",
    "### Load trained StarDist3D model\n",
    "\n",
    "### Parameters\n",
    "- `model_name`: A string specifying the name of the model to reload.\n",
    "\n",
    "### Notes:\n",
    "> By default, the function looks for the model with the specified name from the stardist_models directory. However, if you have saved the model in a different location, you can specify the `basedir` parameter to load the model from that directory.\n",
    "```\n",
    "    model = sdw.load_stardist_model(model_name=stardist_model_name, basedir=\".\\FolderA\\FolderB\\\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stardist_model_name = \"stardist_worm1\"\n",
    "model = sdw.load_stardist_model(model_name=stardist_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment the volume #1 image and save the segmentation in auto_vol1 folder\n",
    "\n",
    "### Parameters\n",
    "- `path_results`: A string specifying a directory to save the segmentation/tracking results.\n",
    "- `path_raw_images`: A string specifying the file path to the raw images.\n",
    "\n",
    "### Notes\n",
    "> All of the time-lapse 3D images should be stored in a single directory. Each 3D image at time t should be saved as a sequence of 2D slices in TIFF format. The filename of each 2D image should contain the timing and slice number, such as \"xxx_txxx_z_xxx.tif\". To ensure that the program correctly loads the images for each timing, users should specify the format of the timing in the filename in the `path_raw_images` parameter. For example, \"t%03d.tif\" indicates that the filename should contain the letter \"t\" followed by a 3-digit number representing the timing, followed by any number of characters, and ending with the extension \".tif\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results = \"results/\"\n",
    "path_raw_images = f\"{base_dir}/large_dataset_slices/*t%04d*.tif\" #folder for the data 2d slices\n",
    "\n",
    "# Load raw image at vol 1\n",
    "vol = 1\n",
    "x = sdw.load_2d_slices_at_time(path_raw_images, t=vol)\n",
    "print(f\"Raw image shape at vol1: {x.shape} {x.dtype}\")\n",
    "\n",
    "# x = tf.cast(x, dtype=tf.int8)\n",
    "print(f\"Raw image shape at vol1: {x.shape} {x.dtype}\")\n",
    "labels, details, prob_map = model.predict_instances_big(x,'ZYX',block_size=(140,250,250),min_overlap=(22, 20, 20),context = 46)\n",
    "use_8_bit = True if labels.max() <= 255 else False\n",
    "\n",
    "sdw.plot_img_label_max_projection(x, labels, lbl_title=\"label pred (projection)\", fig_width_px=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying max projections of raw images and predicted segmentation in x-z plane\n",
    "\n",
    "### Parameters\n",
    "- `scale_z`: A number (>0) specifying the scaling rate along the z-axis. This is useful when the resolution in the z-axis is significantly different from that in the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_z = 1\n",
    "\n",
    "sdw.plot_img_label_max_projection_xz(x, labels, lbl_title=\"label pred (projection)\", fig_width_px=1800, scale_z=scale_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment all volumes \n",
    "The following code block segments cells in all volumes and saves the predicted cell coordinates and probability maps in the \"seg\" folder automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the dictionary\n",
    "block_details = {}\n",
    "\n",
    "# Add values to the dictionary with appropriate keys\n",
    "block_details['block_size'] = (140, 250, 250)\n",
    "block_details['min_overlap'] = (22, 20, 20)\n",
    "block_details['context'] = 46\n",
    "\n",
    "sdw.predict_and_save_big(images_path=path_raw_images, model=model, results_folder=path_results,blocks_details=block_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Manual correction\n",
    "\n",
    "### Perform manual correction\n",
    "- Manually correct the segmentation results saved in the \"auto_vol1\" folder, use software like ITK-SNAP. \n",
    "- Save the corrected segmentation as 2D slices in the TIFF format in the \"manual_vol1\" folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the manually corrected segmentation\n",
    "\n",
    "### Parameters\n",
    "- `voxel_size`: A tuple of 3 numbers, indicating the size (in arbitrary units) of a voxel in the x, y, and z directions.\n",
    "- `manual_seg_path`: A string specifying the file path to the manually corrected segmentation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_folder = \"results/auto_vol1/\"  # Relative path to the auto segmentation\n",
    "destination_folder = \"results/manual_vol1/\"  # Relative path to manual segmentation we just copy the auto segmentation for now\n",
    "\n",
    "# Check if the destination directory exists\n",
    "if os.path.exists(destination_folder):\n",
    "    shutil.rmtree(destination_folder)\n",
    "\n",
    "# Copy the entire folder\n",
    "shutil.copytree(source_folder, destination_folder)\n",
    "\n",
    "print(f\"Folder copied from {source_folder} to {destination_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size=(1, 1, 1)\n",
    "manual_seg_path=\"results/manual_vol1/*.tif\"\n",
    "\n",
    "coords2image = cit.CoordsToImageTransformer(results_folder=path_results, voxel_size=voxel_size)\n",
    "coords2image.load_segmentation(manual_seg_path)\n",
    "sdw.plot_img_label_max_projection(x, coords2image.proofed_segmentation.transpose(2,0,1), lbl_title=\"label proofed (projection)\", fig_width_px=1800)\n",
    "sdw.plot_img_label_max_projection_xz(x, coords2image.proofed_segmentation.transpose(2,0,1), lbl_title=\"label proofed (projection)\", fig_width_px=1800, scale_z=scale_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform interpolation along z axis\n",
    "\n",
    "### Parameters\n",
    "- `interpolation_factor`: An integer parameter (>= 1) that specifies the factor by which the number of z-slices in the original 3D image should be increased. For example, if the original image has 10 z-slices and factor is set to 2, then the new image will have 20 z-slices.\n",
    "\n",
    "### Notes\n",
    "> The interpolated results are used to refine the positions of the tracking results. Increasing the number of z-slices via interpolation can improve the accuracy of the estimated cell positions. \n",
    "\n",
    "> The program employs a Gaussian blur filter to generate the interpolation. Even if the `interpolation_factor` is set to 1, the program still applies the filter without increasing the number of slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_factor = 1\n",
    "\n",
    "coords2image.interpolate(interpolation_factor=interpolation_factor)\n",
    "sdw.plot_img_label_max_projection(x, coords2image.auto_corrected_segmentation.transpose(2,0,1), lbl_title=\"label interpolated (projection)\", fig_width_px=1800)\n",
    "sdw.plot_img_label_max_projection_xz(x, coords2image.auto_corrected_segmentation.transpose(2,0,1), lbl_title=\"label interpolated (projection)\", fig_width_px=1800,scale_z=scale_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Tracking cells. \n",
    "\n",
    "### Initiate Tracker\n",
    "\n",
    "### Parameters\n",
    "- `ffn_model_name`: A string specifying the name of the ffn model to reload.\n",
    "\n",
    "### Notes:\n",
    "> By default, the function looks for the model with the specified name from the \"ffn_models\" directory. However, if you have saved the model in a different location, you can specify the `basedir` parameter to load the model from that directory.\n",
    "```\n",
    "    tracker = trl.TrackerLite(results_dir=path_results, ffn_model_name=ffn_model_name, proofed_coords_vol1=coords2image.coord_vol1, basedir=\".\\FolderA\\FolderB\\\")\n",
    "```    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T09:18:23.326598Z",
     "start_time": "2021-06-01T09:18:23.281754Z"
    }
   },
   "outputs": [],
   "source": [
    "ffn_model_name=\"ffn_worm4\"\n",
    "basedir = f\"{example_dir}/ddsipim/fnn_models\" \n",
    "tracker = trl.TrackerLite(results_dir=path_results, ffn_model_name=ffn_model_name,basedir=basedir, proofed_coords_vol1=coords2image.coord_vol1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FFN matching\n",
    "\n",
    "### Parameters\n",
    "- `t1`: An integer specifying the volume number of the first segmentation\n",
    "- `t2`: An integer specifying the volume number of the second segmentation\n",
    "\n",
    "### Notes:\n",
    ">  The program will match the segmented cell centers points (saved in the \"seg\" folder) between volumes t1 and t2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1\n",
    "t2 = 2\n",
    "\n",
    "tracker.match_by_ffn(t1=t1, t2=t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T04:54:59.219773Z",
     "start_time": "2021-05-14T04:54:59.151351Z"
    }
   },
   "source": [
    "### Test FFN + PR-GLS tracking\n",
    "\n",
    "### Parameters\n",
    "- `beta`: A numeric value (integer or float). A larger value will result in a larger window for estimating cell movement based on neighboring cells.\n",
    "- `lambda_`: A numeric value (integer or float). A larger value will result in more similar movements across different cells.\n",
    "\n",
    "### Notes:\n",
    "> The program will estimate the new positions at time point `t2` for all cells segmented at time point `t1`. The FFN matching will be improved by PR-GLS to generate a more coherent estimation of cell movements.\n",
    "\n",
    "> The default values of `beta` and `lambda_` are (3, 3), which are suitable for most cases. However, users can try different values to further improve the tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 3\n",
    "lambda_= 3\n",
    "\n",
    "tracked_positions_t2 = tracker.predict_cell_positions(t1=t1, t2=t2, beta=beta, lambda_=lambda_, draw_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track cells in following volumes in ensemble mode\n",
    "\n",
    "### Parameters\n",
    "- `t_start`: An integer specifying the volume number of the first raw image. Usually, this value is set to 1, so that the program will load coordinates in volume 2, 3, 4, and so on for tracking. If `t_start` is not 1, then the subsequent volume numbers will be `t_start + 1`, `t_start + 2`, and so on.\n",
    "- `t_end`: An integer specifying the volume number of the last raw image that should be tracked.\n",
    "- `skipped_volumes`: A list of integers specifying the volumes that should be skipped during tracking. An empty list [] means no volume will be skipped.\n",
    "\n",
    "### Notes:\n",
    "> All tracking results will be automatically saved in the \"track_results\" folder, including:\n",
    "> 1. The coordinates of tracked cells (in the same units as the `voxel_size`) - Folder \"coords_real\"\n",
    "> 2. Figures showing the tracking in each volume - Folder \"figure\"\n",
    "> 3. Images of the tracked labels in each volume - Folder \"labels\"\n",
    "> 4. Merged images of the raw image and the tracked labels in each volume, projected on the x-y plane - Folder \"merged_labels\"\n",
    "> 5. Merged images of the raw image and the tracked labels in each volume, projected on the x-z plane - Folder \"merged_labels_xz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T09:18:57.920564Z",
     "start_time": "2021-06-01T09:18:56.606858Z"
    }
   },
   "outputs": [],
   "source": [
    "t_start = 1\n",
    "t_end = 19\n",
    "skipped_volumes = [20]\n",
    "\n",
    "ensemble = True\n",
    "t1 = t_start\n",
    "confirmed_coord = coords2image.coord_vol1\n",
    "grid = model.config.grid\n",
    "for t in range(t_start+1, t_end+1):\n",
    "    print(f\"t={t}...\", end=\"\\r\")\n",
    "    if t in skipped_volumes:\n",
    "        print(f\"skip t={t}\")\n",
    "        continue\n",
    "    coord_prgls = tracker.predict_cell_positions_ensemble(skipped_volumes=skipped_volumes, t2=t, coord_t1=confirmed_coord, beta=beta, lambda_=lambda_, \n",
    "                                                          sampling_number=20, adjacent=False, t_start=t_start)\n",
    "    confirmed_coord, corrected_labels_image = coords2image.accurate_correction(t, grid, coord_prgls, ensemble)\n",
    "    coords2image.save_tracking_results(confirmed_coord, corrected_labels_image, tracker, t1=t1, t2=t, images_path=path_raw_images)\n",
    "    t1 = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Extract activities from tracked cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract activities\n",
    "\n",
    "### Parameters\n",
    "- `raw_path`: A string specifying the file path to the raw image to extract the activities. The image data should be in TIFF format.\n",
    "\n",
    "### Notes\n",
    "> This Code Block extracts activities from 3D time-lapse images, based on tracking results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"*t%04d*.tif\"\n",
    "\n",
    "activities = tracker.activities(raw_path=raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a figure to show the activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_signals(activities, ylim_lower=300, ylim_upper=1200, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the activities as csv file\n",
    "\n",
    "### Parameters\n",
    "- `csv_filename`: The filename of the csv file to save the extracted activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"activities_txcell.csv\"\n",
    "\n",
    "csv_filename = os.path.join(path_results, \"activities_txcell.csv\")\n",
    "timings = np.arange(1, activities.shape[0]+1).reshape(-1, 1)\n",
    "activities_with_timings = np.concatenate((timings, activities), axis=1)\n",
    "headers = ['timing'] + ['cell' + str(i) for i in range(1, activities.shape[1]+1)]\n",
    "np.savetxt(csv_filename, activities_with_timings, delimiter=',', fmt='%.3f', header=','.join(headers), comments='')\n",
    "print(f\"The cell activities have been saved in {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "521.183px",
    "left": "897px",
    "right": "20px",
    "top": "146px",
    "width": "539px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3DeeCellTracker Demo: Train StarDist3D\n",
    "\n",
    "This notebook demonstrates how to train a StarDist3D model for cell segmentation. It is a revised version of a notebook originally from the StarDist project (URL: https://github.com/stardist/stardist/blob/master/examples/3D/2_training.ipynb), which includes programs based on a wrapper written by Chentao Wen for the StarDist package.\n",
    "\n",
    "The demo data used in this notebook can be found in the \"worm1_stardist_training_data\" folder, which can be downloaded from https://osf.io/pgr95/.\"\n",
    "\n",
    "**The basic procedures:**\n",
    "- A. Import packages\n",
    "- B. Load training data\n",
    "- C. Configure StarDist3D model\n",
    "- D. Check data augmentation\n",
    "- E. Train StarDist3D\n",
    "- F. Optimize a threshold for segmentation\n",
    "- G. Confirm the segmentation results with trainied model\n",
    "\n",
    "Please shutdown all other training/prediction notebooks before running this notebook (as those might occupy the GPU memory otherwise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import CellTracker.stardistwrapper as sdw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE THIS FIELDS\n",
    "\n",
    "base_dir = \"/om/user/mansour8/build_demo\"\n",
    "example_dir = F\"{base_dir}/3DeeCellTracker/Examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Load training data\n",
    "This code block is used to load raw images and the corresponding cell annotations for training the StarDist model.\n",
    "\n",
    "### Parameters\n",
    "- `path_train_images`: A string specifying the file path to the raw images.\n",
    "- `path_train_labels`: A string specifying the file path to the annotated label images (where each cell has a different label).\n",
    "\n",
    "### Notes\n",
    ">To specify the file paths for the training images and labels, you need to provide a string that tells the program where to find the images and labels. This string should include a special pattern that matches all files with the extension .tif in the directories where the images and labels are located. This pattern is called a Unix glob pattern and it looks like this: *.tif.\n",
    "\n",
    ">For example, if your training images are located in a directory called \"images\" and your labels are located in a directory called \"labels\", you can specify the file paths like this:\n",
    "\n",
    "```\n",
    "    path_train_images = './images/*.tif'\n",
    "    path_train_labels = './labels/*.tif'\n",
    "```\n",
    "\n",
    ">This tells the program to look for all files with the extension .tif in the \"images\" and \"labels\" directories.\n",
    "\n",
    ">The \"./\" refers to the current working directory that contains this notebook.\n",
    "\n",
    ">In addition, the training images and labels must be saved as 3D image stacks in .tif format, which is required by the \"stardist\" package used in this notebook. The corresponding image and label should have the same filename but in different directories. For example, if the image file is called \"image001.tif\", then the corresponding label file should also be called \"image001.tif\". You can check the downloaded demo data to see examples of how the images and labels are named."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_train_images = f'{base_dir}/dataset_large/train_image/*.tif'\n",
    "path_train_labels = f'{base_dir}/dataset_large/train_label/*.tif'\n",
    "\n",
    "X, Y, X_trn, Y_trn, X_val, Y_val, n_channel = \\\n",
    "    sdw.load_training_images(path_train_images, path_train_labels, max_projection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Configure StarDist3D model\n",
    "This code block create a StarDist3D model for training.\n",
    "\n",
    "### Parameters\n",
    "- `model_name`: A string specifying the filename to save the trained StarDist3D model. This filename will be used to load the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"stardist_worm1\"\n",
    "\n",
    "model = sdw.configure(Y, n_channel, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Check data augmentation\n",
    "Data augmentation is used to create additional data that can improve the accuracy of the StarDist model. This code block displays some samples of the augmented images and labels for verification purposes. By checking the augmented data, you can ensure that the generated images and labels are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot some augmented examples\n",
    "img, lbl = X[0],Y[0]\n",
    "sdw.plot_img_label_max_projection(img, lbl)\n",
    "for _ in range(3):\n",
    "    img_aug, lbl_aug = sdw.augmenter(img,lbl)\n",
    "    sdw.plot_img_label_max_projection(img_aug, lbl_aug, img_title=\"image augmented (projection)\", lbl_title=\"label augmented (projection)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Train StarDist3D\n",
    "\n",
    "### Parameters\n",
    "- `epochs`: An integer specifying the number of epochs for training. A larger number of epochs will require a longer training time. The default value of 500 is a reasonable choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=500\n",
    "\n",
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=sdw.augmenter, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. Threshold optimization\n",
    "While the default values for the probability and non-maximum suppression thresholds already yield good results in many cases, we still recommend to adapt the thresholds to your data. The optimized threshold values are saved to disk and will be automatically loaded with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds([X_val[0]], [Y_val[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. Confirm the segmentation results with trainied model \n",
    "This code block is used to segment cells with the trained StarDist model. The first validation image is segmented and the results are displayed.\n",
    "\n",
    "Note: If only one 3D image/label was provided for training in section B, the segmentation of this training image will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = X_val[0]\n",
    "labels, details,prob_map = model.predict_instances_big(xx,'ZYX',block_size=(140,350,350),min_overlap=(22, 20, 20),context = 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdw.plot_img_label_max_projection(X_val[0],Y_val[0], lbl_title=\"label GT (projection)\")\n",
    "sdw.plot_img_label_max_projection(X_val[0],labels, lbl_title=\"label Pred (projection)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the dataset volumes you want to porcess for the tracing step\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = f\"{base_dir}/dataset_large/train_image/\"  # Replace with your dataset_large directory ex /om/user/mansour8/build_demo/dataset_large/train_image/\n",
    "output_dir = f\"{base_dir}/dataset_large/large_dataset_slices/\"  # Replace with your output directory ex /om/user/mansour8/build_demo/large_dataset_slices\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through all 3D .tif files in the input directory\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        # Extract volume number (assumes filenames like \"3d_data_0001.tif\")\n",
    "        vol_number = filename.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        # Load the 3D dataset\n",
    "        volume = imread(os.path.join(input_dir, filename))\n",
    "        \n",
    "        # Save each slice of the volume as a separate 2D .tif file\n",
    "        for z_idx in range(volume.shape[0]):  # Iterate over z-slices\n",
    "            slice_filename = f\"3d_data_t{vol_number}_{z_idx:04d}.tif\"\n",
    "            slice_path = os.path.join(output_dir, slice_filename)\n",
    "            \n",
    "            # Save the z-slice\n",
    "            imwrite(slice_path, volume[z_idx])\n",
    "            \n",
    "        print(f\"Processed volume {filename}, saved {volume.shape[0]} slices.\")\n",
    "\n",
    "print(\"All volumes have been processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
